{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducibility Project Draft for CS598 DL4H in Spring 2023\n",
    "# Notebook accompanying project draft submission\n",
    "## Author: Martin Tomis\n",
    "## Author email: mtomis2@illinois.edu\n",
    "## Group ID: 69\n",
    "## Paper ID: 149\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a jupyter notebook with my attempt to replicate the model descibed in paper \"Explainable Automated Coding of Clinical Notes using Hierarchical Label-wise Attention Networks and Label Embedding Initialisation by Hang et al.\" The paper introduces a novel solution of a crucial problem - predicting medical codes from Electronic Health Records (EHR).\n",
    "\n",
    "The combination of attention and of leveraging the hierarchy of medical codes leads the authors to describing the solution as ”Hierarchical Label-wise Attention Networks” (HLAN). The authors also use the initialisation of embeddings which captures the correlation among the labels.\n",
    "\n",
    "The key components of the HLAN model are:\n",
    "- Hierarchical: model leverages the structure of a medical code, linking individual words to sentences and sentences to the document.\n",
    "- Label-wise: essentially each code has its own set of parameters.\n",
    "- Attention: attention mechanism is state-of-the-art for many NLP tasks.\n",
    "- Network: these components are connected within a framework of deep-learning model layers.\n",
    "\n",
    "The rest of this notebook describes steps following the preparation of the immediate input files. Preparation of the raw dataset is described in a separate jupyter notebook in this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import csv\n",
    "import os\n",
    "import math\n",
    "import operator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from time import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading inputs\n",
    "This step assumes that data was pre-processed using the instructions in https://github.com/acadTags/Explainable-Automated-Medical-Coding/tree/master/datasets and most importantly, instructions and code provided in https://github.com/jamesmullenbach/caml-mimic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likely due to memory issues, the final model cannot be run on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_train = pd.read_csv(os.path.join(os.getcwd(), \"Data/mimic-iii/train_50.csv\"))\n",
    "notes_train = notes_train.sample(frac=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_test = pd.read_csv(os.path.join(os.getcwd(), \"Data/mimic-iii/test_50.csv\"))\n",
    "notes_test = notes_test.sample(frac=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.read_csv(os.path.join(os.getcwd(), \"Data/mimic-iii/processed_full.embed\"), delimiter=' ', header = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>**PAD**</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000cc</td>\n",
       "      <td>0.031379</td>\n",
       "      <td>-0.016026</td>\n",
       "      <td>-0.007015</td>\n",
       "      <td>0.026159</td>\n",
       "      <td>-0.000628</td>\n",
       "      <td>-0.029135</td>\n",
       "      <td>0.037267</td>\n",
       "      <td>0.026875</td>\n",
       "      <td>0.040712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027516</td>\n",
       "      <td>0.080226</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>-0.039936</td>\n",
       "      <td>0.010744</td>\n",
       "      <td>-0.006892</td>\n",
       "      <td>-0.071733</td>\n",
       "      <td>0.034608</td>\n",
       "      <td>-0.026505</td>\n",
       "      <td>0.020716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000mcg</td>\n",
       "      <td>0.045996</td>\n",
       "      <td>-0.052848</td>\n",
       "      <td>-0.044482</td>\n",
       "      <td>0.045182</td>\n",
       "      <td>0.022560</td>\n",
       "      <td>0.037396</td>\n",
       "      <td>0.026134</td>\n",
       "      <td>0.047924</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020273</td>\n",
       "      <td>0.021479</td>\n",
       "      <td>0.037988</td>\n",
       "      <td>0.075513</td>\n",
       "      <td>0.104129</td>\n",
       "      <td>-0.045498</td>\n",
       "      <td>0.007735</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>-0.024968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000mg</td>\n",
       "      <td>0.250123</td>\n",
       "      <td>0.174383</td>\n",
       "      <td>-0.269695</td>\n",
       "      <td>0.056581</td>\n",
       "      <td>-0.065816</td>\n",
       "      <td>-0.124786</td>\n",
       "      <td>-0.088935</td>\n",
       "      <td>-0.279940</td>\n",
       "      <td>0.048762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206152</td>\n",
       "      <td>0.156756</td>\n",
       "      <td>-0.059231</td>\n",
       "      <td>-0.166126</td>\n",
       "      <td>-0.129042</td>\n",
       "      <td>-0.454636</td>\n",
       "      <td>-0.695260</td>\n",
       "      <td>0.101938</td>\n",
       "      <td>0.059170</td>\n",
       "      <td>-0.231901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000s</td>\n",
       "      <td>0.061875</td>\n",
       "      <td>-0.044950</td>\n",
       "      <td>-0.132188</td>\n",
       "      <td>0.054579</td>\n",
       "      <td>-0.045981</td>\n",
       "      <td>-0.082330</td>\n",
       "      <td>0.084938</td>\n",
       "      <td>0.005535</td>\n",
       "      <td>0.129054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.289205</td>\n",
       "      <td>0.187125</td>\n",
       "      <td>-0.239062</td>\n",
       "      <td>-0.010229</td>\n",
       "      <td>-0.063107</td>\n",
       "      <td>0.296233</td>\n",
       "      <td>-0.024894</td>\n",
       "      <td>-0.179583</td>\n",
       "      <td>-0.183988</td>\n",
       "      <td>-0.052326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6    \\\n",
       "0  **PAD**  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1    000cc  0.031379 -0.016026 -0.007015  0.026159 -0.000628 -0.029135   \n",
       "2   000mcg  0.045996 -0.052848 -0.044482  0.045182  0.022560  0.037396   \n",
       "3    000mg  0.250123  0.174383 -0.269695  0.056581 -0.065816 -0.124786   \n",
       "4     000s  0.061875 -0.044950 -0.132188  0.054579 -0.045981 -0.082330   \n",
       "\n",
       "        7         8         9    ...       91        92        93        94   \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.037267  0.026875  0.040712  ... -0.027516  0.080226  0.007671 -0.039936   \n",
       "2  0.026134  0.047924  0.002321  ... -0.020273  0.021479  0.037988  0.075513   \n",
       "3 -0.088935 -0.279940  0.048762  ...  0.206152  0.156756 -0.059231 -0.166126   \n",
       "4  0.084938  0.005535  0.129054  ... -0.289205  0.187125 -0.239062 -0.010229   \n",
       "\n",
       "        95        96        97        98        99        100  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.010744 -0.006892 -0.071733  0.034608 -0.026505  0.020716  \n",
       "2  0.104129 -0.045498  0.007735  0.000838  0.001557 -0.024968  \n",
       "3 -0.129042 -0.454636 -0.695260  0.101938  0.059170 -0.231901  \n",
       "4 -0.063107  0.296233 -0.024894 -0.179583 -0.183988 -0.052326  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reformatting embeddings so that it can be used by torch function nn.Embedding.from_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.columns = ['WORD'] + [str(i) for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.index = embeddings['WORD']\n",
    "embeddings = embeddings.drop('WORD', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.tensor(embeddings.values) # formerly syn0,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add multi-hot encoding for labels - ensure consistent encoding for Train / Test\n",
    "Current implementation fails on some small subsets if there are not all inputs represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(Y, labels_dict = None, create = False):\n",
    "\n",
    "    if create:\n",
    "        labels_dict = {}\n",
    "        j = 0\n",
    "        for y in Y:\n",
    "            labels = str(y).split(\";\")\n",
    "            for label in labels:\n",
    "                if label not in labels_dict:\n",
    "                    labels_dict[label] = j\n",
    "                    j+=1\n",
    "                \n",
    "    y_tensor = torch.zeros([len(Y), len(labels_dict)])\n",
    "    \n",
    "    for _, y in enumerate(Y):\n",
    "        labels = str(y).split(\";\")\n",
    "        for label in labels:\n",
    "            idx = labels_dict[label]\n",
    "            y_tensor[_, idx] = 1\n",
    "    return y_tensor, labels_dict\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train,labels_dict_ = create_labels(notes_train.LABELS, None, True)\n",
    "Y_test, labels_dict_check = create_labels(notes_test.LABELS,labels_dict_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create word-to-index mapping for assigning embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ids = {}\n",
    "for i, word in enumerate(embeddings.index):\n",
    "    word_to_ids[word] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max length - helper function to get correct dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length(X_):\n",
    "    X = X_.TEXT\n",
    "    j = 0\n",
    "    not_found_words = {}\n",
    "    max_length = 0\n",
    "    for x in X:\n",
    "        words = x.split(' ')\n",
    "\n",
    "        j = 0\n",
    "        for word in words:\n",
    "#            if word in word_to_ids:\n",
    "            j+=1\n",
    "        if j > max_length:\n",
    "            max_length = j\n",
    "    return max_length\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(get_max_length(notes_train),get_max_length(notes_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6120"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6120"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_max_length(notes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5630"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_max_length(notes_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform text to index matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_(row_):\n",
    "    return len(row_['TEXT'].split(' '))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_train['length'] = notes_train.apply(length_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fb0636f3250>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "notes_train.hist(column='length',bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_test['length'] = notes_test.apply(length_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fb063802490>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "notes_test.hist(column='length',bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_tensor(X_, max_length, word_to_ids):\n",
    "    index_tensor = torch.zeros([X_.shape[0], max_length])\n",
    "    \n",
    "    for i, row in enumerate(X_):\n",
    "        words = row.split(' ')[:max_length]\n",
    "        for j, word in enumerate(words):\n",
    "            if word in word_to_ids:\n",
    "                index_tensor[i,j] = word_to_ids[word]\n",
    "    return index_tensor\n",
    "                \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index_tensor_train = create_index_tensor(notes_train.TEXT, 4000, word_to_ids)\n",
    "#index_tensor_test =  create_index_tensor(notes_test.TEXT, 4000, word_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_tensor_train = create_index_tensor(notes_train.TEXT, max_length, word_to_ids)\n",
    "index_tensor_test =  create_index_tensor(notes_test.TEXT, max_length, word_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4406., 14227., 15751.,  ...,     0.,     0.,     0.],\n",
       "        [ 4406., 14227., 15751.,  ...,     0.,     0.,     0.],\n",
       "        [ 4406., 14227., 15751.,  ...,     0.,     0.,     0.],\n",
       "        ...,\n",
       "        [ 4406., 14227., 15751.,  ...,     0.,     0.,     0.],\n",
       "        [ 4406., 14227., 15751.,  ...,     0.,     0.,     0.],\n",
       "        [ 4406., 14227., 15751.,  ...,     0.,     0.,     0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_tensor_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similar steps as in HLAN paper - word encoder (first part). Splitting of notes into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = nn.Embedding.from_pretrained(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_embed_reshape(X_indices,embeddings, chunk_size, Y):\n",
    "    # split\n",
    "    \n",
    "    x_tensor = []\n",
    "    y_tensor = []\n",
    "    max_l = 0\n",
    "    \n",
    "    for _, row in enumerate(X_indices):\n",
    "        row_chunks = list(torch.split(row, chunk_size))\n",
    "        if max_l < len(row_chunks):\n",
    "            max_l = len(row_chunks)\n",
    "            max_index = _\n",
    "        all_zero_index = []\n",
    "        non_zero_counter = 0\n",
    "        for i, row_chunk in enumerate(row_chunks):\n",
    "            if torch.all(row_chunk==0.0):\n",
    "                all_zero_index.append(i)\n",
    "            else:\n",
    "                all_zero_index.append(0)\n",
    "                non_zero_counter += 1\n",
    "        if len(row_chunk) != chunk_size:\n",
    "            row_chunks[i] = torch.cat((row_chunk, torch.zeros(chunk_size-len(row_chunk))))\n",
    "         \n",
    "        if non_zero_counter == 0:\n",
    "            print(\"non_zero_counter is 0\")\n",
    "            y = torch.vstack([Y[_]]* 1)\n",
    "        else:\n",
    "            y = torch.vstack([Y[_]]* non_zero_counter)\n",
    "            \n",
    "            \n",
    "        for idx in sorted(all_zero_index, reverse = True):\n",
    "            if idx != 0:\n",
    "                del row_chunks[idx]\n",
    "         \n",
    "        # embed\n",
    "        embedding_vectors =[]\n",
    "        for row_chunk in row_chunks:\n",
    "            #print(row_chunk.to(torch.long))\n",
    "            embedding_vectors.append(embeddings(row_chunk.to(torch.long)))\n",
    "        x_embeddings = torch.vstack(embedding_vectors)\n",
    "        x_embeddings = torch.reshape(x_embeddings, (len(row_chunks) ,chunk_size,  100))\n",
    "        x_tensor.append(x_embeddings)\n",
    "        \n",
    "        y_tensor.append(y)\n",
    "        \n",
    "    return torch.vstack(x_tensor).to(torch.double),torch.vstack(y_tensor).to(torch.double), max_l, max_index\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, ml, mi = split_embed_reshape(index_tensor_train, embeds, 50, Y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test, ml, mi  = split_embed_reshape(index_tensor_test, embeds, 50, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mine architecture\n",
    "\n",
    "Hierarchical structure should be is as follows:¶\n",
    "1. Word Encoder - Bi-Directional GRU, preceeded by procedding shown above.\n",
    "2. Word-level Attention - attention - detailed comments are in the attention_word_level_ method below.\n",
    "3. Sentence Encoder - Bi-Directional GRU, \n",
    "4. Sentence-level Attention - detailed comments are in the attention_sentence_level_ method below.\n",
    "5. Linear classifier.\n",
    "\n",
    "The original paper shows the architecture as follows:\n",
    "\n",
    "\n",
    "![image](HLAN-architecture.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAN(nn.Module):\n",
    "    \n",
    "    def __init__(self, chunk_size = 50, embedding_dim=100, num_classes = 50, sentence_dim = 10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn_naive = nn.GRU(embedding_dim, embedding_dim, batch_first=True)\n",
    "\n",
    "        self.gru_word_level = nn.GRU(embedding_dim, embedding_dim, 1, batch_first=True,bidirectional=False)\n",
    "        self.gru_sentence_level = nn.GRU(sentence_dim, sentence_dim, 1, batch_first=True,bidirectional=False)\n",
    "\n",
    "    \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.chunk_size = chunk_size\n",
    "        self.sentence_dim = sentence_dim\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.hidden_size = 10\n",
    "        self.softmax_logit = nn.Softmax(dim=1)\n",
    "        \n",
    "        self.context_word_att = nn.Linear(2* self.embedding_dim, 2*self.embedding_dim)\n",
    "        self.context_sentence_att = nn.Linear(2* self.sentence_dim, 2*self.sentence_dim)\n",
    "        self.fc = nn.Linear(2*self.sentence_dim, self.num_classes)\n",
    "        self.fc_naive =  nn.Linear(embedding_dim*2, num_classes)\n",
    "        \n",
    "        \n",
    "    def gru_backward_word_level_(self, x):\n",
    "        h_t_backward_list = []\n",
    "        for _, row in enumerate(x):\n",
    "            embedded_words_splitted = list(torch.split(row, self.chunk_size))\n",
    "            embedded_words_squeeze = [torch.squeeze(x, axis=1) for x in embedded_words_splitted]\n",
    "            embedded_words_squeeze.reverse()\n",
    "            h_t = torch.ones_like(embedded_words_squeeze[0])\n",
    "            h_t = torch.unsqueeze(h_t, 0)\n",
    "\n",
    "            \n",
    "            temp_list = []\n",
    "\n",
    "\n",
    "            for time_step, Xt in enumerate(embedded_words_squeeze):\n",
    "                Xt = torch.unsqueeze(Xt, 0)\n",
    "                Xt = torch.reshape(h_t, (Xt.shape[1], Xt.shape[0],Xt.shape[2] ))\n",
    "                output, h_t = self.gru_word_level(Xt.float(), h_t.float())\n",
    "                temp_list.append(torch.squeeze(h_t, 0))\n",
    "            temp_list.reverse()\n",
    "            h_t_backward_list.extend(temp_list)\n",
    "        return h_t_backward_list\n",
    "    \n",
    "    def gru_forward_word_level_(self, x):\n",
    "        h_t_forward_list = []\n",
    "        for _, row in enumerate(x):\n",
    "            embedded_words_splitted = list(torch.split(row, self.chunk_size))\n",
    "            embedded_words_squeeze = [torch.squeeze(x, axis=1) for x in embedded_words_splitted]\n",
    "            \n",
    "            h_t = torch.ones_like(embedded_words_squeeze[0])\n",
    "            h_t = torch.unsqueeze(h_t, 0)\n",
    "            \n",
    "            temp_list = []\n",
    "\n",
    "            for time_step, Xt in enumerate(embedded_words_squeeze):\n",
    "                Xt = torch.unsqueeze(Xt, 0)\n",
    "                Xt = torch.reshape(h_t, (Xt.shape[1], Xt.shape[0],Xt.shape[2] ))\n",
    "                output, h_t = self.gru_word_level(Xt.float(), h_t.float())\n",
    "                temp_list.append(torch.squeeze(h_t, 0))\n",
    "            temp_list.reverse()\n",
    "            h_t_forward_list.extend(temp_list)    \n",
    "        return h_t_forward_list\n",
    "\n",
    "    def gru_forward_sentence_level_(self, x):\n",
    "        h_t_forward_list = []\n",
    "        for _, row in enumerate(x):\n",
    "            sentence_representation_splitted  = list(torch.split(row, 200))\n",
    "            sentence_representation_squeeze = sentence_representation_splitted#[torch.squeeze(x, axis=1) for x in sentence_representation_splitted ]\n",
    "            h_t = torch.ones_like(sentence_representation_squeeze[0])\n",
    "            h_t = torch.unsqueeze(h_t, 0)\n",
    "            h_t = torch.ones([1, 200, self.sentence_dim])\n",
    "            temp_list = []\n",
    "\n",
    "            for time_step, Xt in enumerate(sentence_representation_squeeze):\n",
    "\n",
    "                Xt = torch.unsqueeze(Xt, 1)\n",
    "                Xt = torch.unsqueeze(Xt, 2)\n",
    "                \n",
    "                Xt_extended = Xt.repeat(1, 1, self.sentence_dim)\n",
    "                Xt = Xt_extended\n",
    "                    \n",
    "                output, h_t = self.gru_sentence_level(Xt.float(), h_t.float())\n",
    "                temp_list.append(torch.squeeze(h_t, 0))\n",
    "            #temp_list.reverse()\n",
    "            h_t_forward_list.extend(temp_list)    \n",
    "        return h_t_forward_list\n",
    "        \n",
    "    def gru_backward_sentence_level_(self, x):\n",
    "        h_t_forward_list = []\n",
    "        for _, row in enumerate(x):\n",
    "            sentence_representation_splitted  = list(torch.split(row, 200))\n",
    "            sentence_representation_squeeze = sentence_representation_splitted#[torch.squeeze(x, axis=1) for x in sentence_representation_splitted ]\n",
    "            \n",
    "            h_t = torch.ones_like(sentence_representation_squeeze[0])\n",
    "            h_t = torch.unsqueeze(h_t, 0)\n",
    "            h_t = torch.ones([1, 200, self.sentence_dim])\n",
    "            temp_list = []\n",
    "\n",
    "            for time_step, Xt in enumerate(sentence_representation_squeeze):\n",
    "                Xt = torch.unsqueeze(Xt, 1)\n",
    "                Xt = torch.unsqueeze(Xt, 2)\n",
    "                \n",
    "                Xt_extended = Xt.repeat(1, 1, self.sentence_dim)\n",
    "                \n",
    "                Xt = Xt_extended\n",
    " \n",
    "                output, h_t = self.gru_sentence_level(Xt.float(), h_t.float())\n",
    "                temp_list.append(torch.squeeze(h_t, 0))\n",
    "            temp_list.reverse()\n",
    "            h_t_forward_list.extend(temp_list)    \n",
    "        return h_t_forward_list\n",
    "            \n",
    "        \n",
    "    def attention_word_level_(self, hidden_state):\n",
    "        hidden_state_ = torch.stack(hidden_state, axis=0)\n",
    "        # Attention:\n",
    "        # 1. Multiply each element of a sentence by matrix (using feed-forward network)\n",
    "        # 2. Pass through tanh (in paper)\n",
    "        # 3. Calculate similarity of the input (hidden state) and output of tanh (transformed context)\n",
    "        # 4. Sum by last dimension (will remain batch x lengt of sentence) and get max by penultimate dimension (label) \n",
    "        # 1.\n",
    "        new_context = self.context_word_att(hidden_state_)\n",
    "        # 2.\n",
    "        tan_output_word = torch.tanh(new_context)\n",
    "        # 3. \n",
    "        hidden_state_context_similiarity = hidden_state_.mul(tan_output_word)\n",
    "        \n",
    "        # 4. \n",
    "        attention_logits = torch.sum(hidden_state_context_similiarity, axis=2) \n",
    "        attention_logits_max = torch.max(attention_logits, dim=1, keepdim=True)\n",
    "        attention_logits_max = attention_logits_max.values.repeat(1,attention_logits.shape[1])\n",
    "\n",
    "        p_attention = self.softmax_logit(attention_logits - attention_logits_max)\n",
    "\n",
    "        p_attention_expanded = torch.unsqueeze(p_attention, axis=2)\n",
    "\n",
    "        sentence_representation = torch.mul(p_attention_expanded, hidden_state_)\n",
    "\n",
    "        sentence_representation = torch.sum(sentence_representation, axis=1)                                     \n",
    "        return sentence_representation  \n",
    "\n",
    "    def attention_sentence_level_(self, hidden_state):\n",
    "        hidden_state_ = torch.stack(hidden_state, axis=0)\n",
    "        # Attention:\n",
    "        # 1. Multiply each element of a sentence by matrix (using feed-forward network)\n",
    "        # 2. Pass through tanh (in paper)\n",
    "        # 3. Calculate similarity of the input (hidden state) and output of tanh (transformed context)\n",
    "        # 4. Sum by last dimension (will remain batch x lengt of sentence) and get max by penultimate dimension (label) \n",
    "        # 1.\n",
    "        new_context = self.context_sentence_att(hidden_state_)\n",
    "        # 2.\n",
    "        tan_output_word = torch.tanh(new_context)\n",
    "        # 3. \n",
    "        hidden_state_context_similiarity = hidden_state_.mul(tan_output_word)\n",
    "        \n",
    "        # 4. \n",
    "        attention_logits = torch.sum(hidden_state_context_similiarity, axis=2) \n",
    "        attention_logits_max = torch.max(attention_logits, dim=1, keepdim=True)\n",
    "        attention_logits_max = attention_logits_max.values.repeat(1,attention_logits.shape[1])\n",
    "\n",
    "        p_attention = self.softmax_logit(attention_logits - attention_logits_max)\n",
    "\n",
    "        p_attention_expanded = torch.unsqueeze(p_attention, axis=2)\n",
    "\n",
    "        sentence_representation = torch.mul(p_attention_expanded, hidden_state_)\n",
    "\n",
    "        sentence_representation = torch.sum(sentence_representation, axis=1)                                     \n",
    "        return sentence_representation \n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 1. Rest of Word Encoder\n",
    "        hidden_state_back = self.gru_backward_word_level_(x)\n",
    "        hidden_state_for = self.gru_forward_word_level_(x)\n",
    "\n",
    "        hidden_state_combined_gru = [torch.cat([h_forward, h_backward], axis=1) for h_forward, h_backward in\n",
    "                             zip(hidden_state_for, hidden_state_back)]\n",
    "        \n",
    "\n",
    "        \n",
    "        # 2.Word Attention\n",
    "        # for each sentence.\n",
    "\n",
    "        sentence_representation = self.attention_word_level_(hidden_state_combined_gru)\n",
    "        \n",
    "        # 3. Sentence-level GRU\n",
    "        hidden_state_forward_sentences = self.gru_forward_sentence_level_(sentence_representation)\n",
    "        hidden_state_backward_sentences = self.gru_backward_sentence_level_(sentence_representation)\n",
    "\n",
    "        \n",
    "        hidden_state_combined_gru = [torch.cat([h_forward, h_backward], axis=1) for h_forward, h_backward in\n",
    "                             zip(hidden_state_forward_sentences, hidden_state_backward_sentences)]\n",
    "        \n",
    "        # 4. Sentence-level attention\n",
    "        document_representation = self.attention_sentence_level_(hidden_state_combined_gru) \n",
    "        \n",
    "        # 5. Linear Classifier\n",
    "\n",
    "        logits = self.fc(document_representation)\n",
    "        \n",
    "        probs = self.sigmoid(logits)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return probs.squeeze(dim=-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HAN(\n",
       "  (rnn_naive): GRU(100, 100, batch_first=True)\n",
       "  (gru_word_level): GRU(100, 100, batch_first=True)\n",
       "  (gru_sentence_level): GRU(10, 10, batch_first=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax_logit): Softmax(dim=1)\n",
       "  (context_word_att): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (context_sentence_att): Linear(in_features=20, out_features=20, bias=True)\n",
       "  (fc): Linear(in_features=20, out_features=50, bias=True)\n",
       "  (fc_naive): Linear(in_features=200, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 0\n",
      "This epoch took 2.0 minutes and 37.268986225128174 seconds.\n",
      "Epoch number: 1\n",
      "This epoch took 2.0 minutes and 46.422897815704346 seconds.\n",
      "Epoch number: 2\n",
      "This epoch took 2.0 minutes and 37.632731199264526 seconds.\n",
      "Epoch number: 3\n",
      "This epoch took 2.0 minutes and 40.94078183174133 seconds.\n",
      "Epoch number: 4\n",
      "This epoch took 2.0 minutes and 39.99514079093933 seconds.\n",
      "Epoch number: 5\n",
      "This epoch took 2.0 minutes and 37.830681800842285 seconds.\n",
      "Epoch number: 6\n",
      "This epoch took 2.0 minutes and 38.94284272193909 seconds.\n",
      "Epoch number: 7\n",
      "This epoch took 2.0 minutes and 38.49711799621582 seconds.\n",
      "Epoch number: 8\n",
      "This epoch took 2.0 minutes and 38.148216009140015 seconds.\n",
      "Epoch number: 9\n",
      "This epoch took 2.0 minutes and 38.240350008010864 seconds.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "batch_losses = []\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Epoch number: {}\".format(epoch))\n",
    "    t0 = time()\n",
    "    for i in range(0, len(X_train), BATCH_SIZE):\n",
    "        x, y = X_train[i:i+BATCH_SIZE], Y_train[i:i+BATCH_SIZE]\n",
    "        #print(\"y\")\n",
    "        #print(y.shape) 32 x 50\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x.float())\n",
    "        loss = criterion(y_hat, y.type(torch.float))\n",
    "        batch_loss_value = loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_losses.append(batch_loss_value)\n",
    "    t1 = time()\n",
    "    print(f\"This epoch took {(t1 - t0) // 60} minutes and {(t1 - t0) % 60} seconds.\")\n",
    "    '''y_hat = model(X_train.float())\n",
    "    pred = np.array(y_hat > 0.5, dtype=float)\n",
    "    auc= roc_auc_score(Y_train, y_hat.detach().numpy(), average='macro')\n",
    "    print(\"Training data AUC is {}\".format(auc))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data AUC is 0.49999719809470444\n"
     ]
    }
   ],
   "source": [
    "y_hat = model(X_test.float())\n",
    "pred = np.array(y_hat > 0.5, dtype=float)\n",
    "auc= roc_auc_score(Y_test, y_hat.detach().numpy(), average='macro')\n",
    "print(\"Testing data AUC is {}\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data AUC is 0.5\n"
     ]
    }
   ],
   "source": [
    "y_hat = model(X_train.float())\n",
    "pred = np.array(y_hat > 0.5, dtype=float)\n",
    "auc= roc_auc_score(Y_train, y_hat.detach().numpy(), average='macro')\n",
    "print(\"Training data AUC is {}\".format(auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
